{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "323c4a86-a69d-4b72-801e-ca3574399fc9"
   },
   "source": [
    "# WML-A Job Submission via WML-A CLI\n",
    "\n",
    "Offical examples can be found here: https://wmla-console-cpd-wmla.apps.cpd.mskcc.org/ui/#/cliTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9a0475e8-bcb3-4424-8c39-873935847fc4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DIR=/userfs\n",
      "env: NAMESPACE=cpd\n",
      "env: HOST=wmla-console-cpd.apps.cpd.mskcc.org\n",
      "env: BASE_URL=https://cpd-cpd.apps.cpd.mskcc.org\n",
      "env: dlicmd=wmla-utils/dlicmd.py\n",
      "env: VOLUME_DISPLAY_NAME=cpd::demo-project-pvc\n"
     ]
    }
   ],
   "source": [
    "%env DIR=/userfs\n",
    "%env NAMESPACE=cpd\n",
    "%env HOST=wmla-console-cpd.apps.cpd.mskcc.org\n",
    "%env BASE_URL=https://cpd-cpd.apps.cpd.mskcc.org\n",
    "\n",
    "%env dlicmd=wmla-utils/dlicmd.py\n",
    "\n",
    "%env VOLUME_DISPLAY_NAME=cpd::demo-project-pvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5b383562-c544-48a5-8bc2-89001a46398b"
   },
   "source": [
    "### Submit Jobs\n",
    "#### PyTorch (single GPU or multiple GPUs on one node with multithreading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "b58687a3-7084-416c-a2ac-e1dc3bd2a032",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DIR_job_submission=/userfs/job_submission\n",
      "env: file_exec=train_command.py\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/Datasets'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/deepliif'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/DeepLIIF_Statistics'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/docs'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/images'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/model-server'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/Registration'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/Sample_Large_Tissues'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/Scripts'\n"
     ]
    }
   ],
   "source": [
    "%env DIR_job_submission=/userfs/job_submission\n",
    "%env file_exec=train_command.py\n",
    "\n",
    "!rm -rf $DIR_job_submission\n",
    "!mkdir -p $DIR_job_submission\n",
    "\n",
    "!cp -r $DIR/deepliif-repo/deepliif $DIR_job_submission\n",
    "!cp $DIR/deepliif-repo/* $DIR_job_submission\n",
    "!cp $DIR/$file_exec $DIR_job_submission\n",
    "!cp $DIR/monitor_gpu.sh $DIR_job_submission\n",
    "!cp $DIR/download_data.sh $DIR_job_submission\n",
    "!cp $DIR/storage_volume_utils.py $DIR_job_submission\n",
    "!cp $DIR/cpd_utils.py $DIR_job_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "id": "c35c45d6-49e2-4c08-9b65-006a52ff04a2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying files and directories ...\n",
      "Content size: 64.2K\n",
      "{\n",
      "  \"execId\": \"cpd-77\",\n",
      "  \"appId\": \"cpd-77\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!python $dlicmd --exec-start PyTorch --rest-host $HOST --rest-port -1 --jwt-token $USER_ACCESS_TOKEN \\\n",
    "                  --msd-env USER_ACCESS_TOKEN=$USER_ACCESS_TOKEN --msd-env BASE_URL=$BASE_URL \\\n",
    "                  --msd-env VOLUME_DISPLAY_NAME=$VOLUME_DISPLAY_NAME \\\n",
    "                  --workerDeviceNum 1 --workerMemory 8g \\\n",
    "                  --model-dir $DIR_job_submission --model-main $file_exec \\\n",
    "                  --cs-datastore-meta type=fs,data_path=DeepLIIF_Datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08726af6-6869-469d-9a1b-67b8af1dbe9c"
   },
   "source": [
    "### Submit Jobs\n",
    "#### distPyTorch (multiprocessing using DDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "id": "fb7d476a-4793-40c3-987b-316ea42c222c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DIR_job_submission=/userfs/job_submission\n",
      "env: file_exec=train_command.py\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/Datasets'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/deepliif'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/DeepLIIF_Statistics'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/docs'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/images'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/model-server'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/Registration'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/Sample_Large_Tissues'\n",
      "cp: -r not specified; omitting directory '/userfs/deepliif-repo/Scripts'\n"
     ]
    }
   ],
   "source": [
    "%env DIR_job_submission=/userfs/job_submission\n",
    "%env file_exec=train_command.py\n",
    "\n",
    "!rm -rf $DIR_job_submission\n",
    "!mkdir -p $DIR_job_submission\n",
    "\n",
    "!cp -r $DIR/deepliif-repo/deepliif $DIR_job_submission\n",
    "!cp $DIR/deepliif-repo/* $DIR_job_submission\n",
    "!cp $DIR/$file_exec $DIR_job_submission\n",
    "!cp $DIR/monitor_gpu.sh $DIR_job_submission\n",
    "!cp $DIR/download_data.sh $DIR_job_submission\n",
    "!cp $DIR/storage_volume_utils.py $DIR_job_submission\n",
    "!cp $DIR/cpd_utils.py $DIR_job_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "id": "651534a9-82d7-492e-9ba6-5b85f93e47b0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /userfs/conf_distPyTorch.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /userfs/conf_distPyTorch.py\n",
    "import os\n",
    "import torch.distributed as dist\n",
    "def init_process():\n",
    "    dist.init_process_group(\n",
    "        backend='nccl',\n",
    "        init_method='tcp://' + os.environ['MASTER_ADDR'] + ':' + os.environ['MASTER_PORT'],\n",
    "        rank=int(os.environ['RANK']),\n",
    "        world_size=int(os.environ['WORLD_SIZE']))\n",
    "    \n",
    "print('------ initiate process group... ------')\n",
    "init_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "id": "fdc36f33-1cee-4dca-9d02-3160ae210a80",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cat cannot change file in place, so we create a new one and use it to overwrite cli.py\n",
    "!cat /userfs/conf_distPyTorch.py $DIR_job_submission/cli.py > $DIR_job_submission/cli_edited.py\n",
    "!mv $DIR_job_submission/cli_edited.py $DIR_job_submission/cli.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "id": "a90893c6-f5f9-4778-8f85-254a2ce53c96",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying files and directories ...\n",
      "Content size: 64.2K\n",
      "{\n",
      "  \"execId\": \"cpd-83\",\n",
      "  \"appId\": \"cpd-83\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!python $dlicmd --exec-start distPyTorch --rest-host $HOST --rest-port -1 --jwt-token $USER_ACCESS_TOKEN \\\n",
    "                  --msd-env USER_ACCESS_TOKEN=$USER_ACCESS_TOKEN --msd-env BASE_URL=$BASE_URL \\\n",
    "                  --msd-env VOLUME_DISPLAY_NAME=$VOLUME_DISPLAY_NAME \\\n",
    "                  --numWorker 6 --workerMemory 8g \\\n",
    "                  --model-dir $DIR_job_submission --model-main $file_exec \\\n",
    "                  --data-source '[{\"type\":\"fs\", \"location\":{\"volume\":\"cpd::demo-project-pvc\"}}]' \\\n",
    "                  --data-source '[{\"type\":\"fs\", \"location\":{\"volume\":\"DeepLIIFData\"}}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "id": "04333f2f-c210-46b7-9332-5c523a233b34",
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (4148379961.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [404]\u001b[0;36m\u001b[0m\n\u001b[0;31m    data_source = '[{\"type\": \"connection\", \"asset\": {\"asset_id\": \"ea76a8f1-eab8-4a00-8bf3-ce31ade3fdc4\", \"project_id\": \"e008ff36-c41d-4f57-968f-639f9b5bb229\"}, \"location\": {\"paths\": \"t10k-labels-idx1-ubyte.gz, model-wl5zj11q/training-output.json\", \"bucket\": \"cos-demo-more\"}}]’\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "data_source = '[{\"type\": \"connection\", \"asset\": {\"asset_id\": \"ea76a8f1-eab8-4a00-8bf3-ce31ade3fdc4\", \"project_id\": \"e008ff36-c41d-4f57-968f-639f9b5bb229\"}, \"location\": {\"paths\": \"t10k-labels-idx1-ubyte.gz, model-wl5zj11q/training-output.json\", \"bucket\": \"cos-demo-more\"}}]’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82024c2c-cb7a-413d-b6f4-42aa8beb4e84"
   },
   "source": [
    "#### Specify Job/App ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "id": "222dd2d5-57b3-4e6a-813f-f7bc9133c194",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: APP_ID=cpd-83\n"
     ]
    }
   ],
   "source": [
    "%env APP_ID=cpd-83"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10ab43f9-45c9-443c-836e-70b8d93201a5"
   },
   "source": [
    "### Delete Jobs (and associated results/logs)\n",
    "#### delete one job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "id": "9187399d-98df-4842-ae9f-03d83db495e7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python $dlicmd.py --exec-delete $NAMESPACE-76 --rest-host $HOST --rest-port -1 --jwt-token $USER_ACCESS_TOKEN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bd3a390-7342-440f-9eab-9f81724edc34"
   },
   "source": [
    "#### delete multiple jobs in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "839e4708-ebe6-47e9-824a-7ed55715859f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: i=70\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=71\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=72\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=73\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=74\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=75\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=76\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=77\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=78\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=79\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=80\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=81\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=82\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=83\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=84\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=85\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=86\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=87\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=88\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=89\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=90\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=91\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=92\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=93\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=94\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=95\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=96\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=97\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n",
      "env: i=98\n",
      "Usage:\n",
      "   python dlicmd.py --help\n",
      "   python dlicmd.py --logon <connection-options> <logon-options>\n",
      "   python dlicmd.py --dl-frameworks | --exec-get-all | --exec-delete-all <connection-options>\n",
      "   python dlicmd.py --exec-start <framework-name> <connection-options> <datastore-meta> <submit-arguments>\n",
      "   python dlicmd.py --exec-get | --exec-stop | --exec-delete <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-deploy <connection-options> <deploy-arguments>\n",
      "   python dlicmd.py --exec-launcherlogs | --exec-outlogs | --exec-errlogs <exec-id> <connection-options>\n",
      "   python dlicmd.py --exec-trainlogs | --exec-trainoutlogs |--exec-trainerrlogs | --exec-trainresult <exec-id> <connection-options>\n",
      "\n",
      "Commands:\n",
      "   --help               Print help message.\n",
      "   --logon              Logs the user onto IBM Watson Machine Learning Accelerator\n",
      "   --dl-frameworks      List available deep learning frameworks for exec.\n",
      "   --exec-start         Submit a deep learning exec.\n",
      "   --exec-get-all       Get all deep learning execs for current user.\n",
      "   --exec-get           Show info for a deep learning exec\n",
      "   --exec-stop          Stop a deep learning exec.\n",
      "   --exec-deploy        Deploy a deep learning exec.\n",
      "   --exec-delete        Delete a deep learning exec.\n",
      "   --exec-delete-all    Delete all deep learning execs for current user.\n",
      "   --exec-launcherlogs  Get launcher logs for a deep learning exec.\n",
      "   --exec-outlogs       Get output logs for a deep learning exec.\n",
      "   --exec-errlogs       Get error logs for a deep learning exec.\n",
      "   --exec-trainlogs     Get train logs for a deep learning exec.\n",
      "   --exec-trainoutlogs  Get train stdout log for a deep learning exec.\n",
      "   --exec-trainerrlogs  Get train stderr log for a deep learning exec.\n",
      "   --exec-trainresult   Get train result for a deep learning exec.\n",
      "\n",
      "Connect-options:\n",
      "   --rest-host          Required. FQDN of IBM Watson Machine Learning Accelerator REST host.\n",
      "   --rest-port          Required. IBM Watson Machine Learning Accelerator REST port. Enter -1 for OCP route.\n",
      "Logon-options:\n",
      "   --username            Logon user name. Required for --logon command.\n",
      "   --password            Logon user password. Required for --logon command.\n",
      "\n",
      "Datastore-meta:\n",
      "   --cs-datastore-meta   Optional. Comma-separated string of name-value pairs. Acceptable names and values are:\n",
      "                            type: 'fs'\n",
      "                            data_path: Only needed for --exec-start option.\n",
      "                                       For 'fs' type, this is relative path to data file system (DLI_DATA_FS)\n",
      "   --data-source         Optional. Json string to describe a list of data sources. Refer to training API documentation for the format of a data source.\n",
      "                             Use either this option or --cs-datastore-meta, and data-source will be used if both options are provided.\n",
      "\n",
      "deploy-arguments:\n",
      "   --name           Optional. Deployed model name\n",
      "   --runtime        Optional. Runtime to load the deployed model\n",
      "   --kernel         Required. Deployed model kernel file\n",
      "   --weight         Optional. Deployed model weight\n",
      "   --tag            Optional. Tag the deployed model\n",
      "   --attributes     Optional. Additional attributes required during model serving\n",
      "   --envs           Optional. Additional environment variables required during model serving\n",
      "\n",
      "Submit-basic-arguments:\n",
      "   <framework-name>      Required. Name of a deep learning framework returned by --dl-frameworks command.\n",
      "   --model-main          Required. Main model file name.\n",
      "   --model-dir           Optional. Path to a directory containing the deep learning model specified in --model-main.\n",
      "   --pbmodel-name        Optional. Name of a prebuilt model such as AlexNet, VGG from TorchVision for PyTorch. You either specify\n",
      "                             this option or --model-main option. You can get more info by running --dl-frameworks.\n",
      "   --appName             Optional. Application name.\n",
      "   --consumer            Optional. Consumer path.\n",
      "   --conda-env-name      Optional. Anaconda environment name to activate.\n",
      "   --numWorker           Optional. Worker number\n",
      "   --workerDeviceType    Optional. Worker device type. cpu or gpu\n",
      "   --workerDeviceNum     Optional. Worker device number\n",
      "   --workerMemory        Optional. Worker memory\n",
      "   --workerCPULimit      Optional. Worker CPU limit. For pack job only\n",
      "   --workerMemoryLimit   Optional. Worker memory limit. For pack job only\n",
      "   --driverDeviceType    Optional. Driver device type. cpu or gpu\n",
      "   --driverDeviceNum     Optional. Driver device number\n",
      "   --driverMemory        Optional. Driver memory\n",
      "   --driverCPULimit      Optional. Driver CPU limit. For pack job only\n",
      "   --driverMemoryLimit   Optional. Driver memory limit. For pack job only\n",
      "\n",
      "Submit-metric-arguments:\n",
      "   --cs-rmq-meta         Optional. RabbitMQ info for metric forwarding. Comma-separated string of name-value pairs.\n",
      "   --cs-url-meta         Optional. Rest URL for metric forwarding.\n",
      "   --cs-url-bearer       Optional. Bearer token for metric forwarding.\n",
      "\n",
      "Submit-advance-arguments:\n",
      "   --msd-env                         Optional. Environment variable. --msd-env <name>=<value>\n",
      "   --msd-attr                        Optional. Attribute variable. --msd-attr <name>=<value>\n",
      "   --msd-image-name                  Optional. Docker image for woker pod.\n",
      "   --msd-image-pull-secret           Optional. The secret name to pull docker image for woker pod.\n",
      "   --msd-image-pull-policy           Optional. The policy to pull docker image for woker pod.\n",
      "   --msd-priority                    Optional. Job priority, an valid integer greater than 0\n",
      "   --msd-task0-node-selector         Optional. Node selector for task0 pod.\n",
      "   --msd-task12n-node-selector       Optional. Node selector for task12n pod.\n",
      "   --msd-pending-timeout             Optional. Job pending timeout in seconds.\n",
      "   --lsf-gpu-syntax                  Optional. LSF gpu syntax to require gpu resource from LSF.\n",
      "   --msd-podaffinity-rule            Optional. Pod affinity rule. preferred or required\n",
      "   --msd-podaffinity-topology-key    Optional. Pod affinity topology key. which is the key for the node label that the system uses to denote such a topology domain\n",
      "   --msd-pack-id                     Optional. Pack id for the job.\n",
      "   [options]             Any model specific options.\n",
      "\n",
      "Other options:\n",
      "   --jwt-token           Optional. JSON web token.\n",
      "   --debug-level         Optional. Log level. Choices are: debug, info, warn, error\n",
      "   --query-args          Optional. Rest query arguments. Only use with --exec-get-all and --hpo-get-all command.\n",
      "\n",
      "Examples:\n",
      "   $ python dlicmd.py --logon --rest-host abc.ibm.com rest-port -1 --username Admin --password Admin\n",
      "   $ python dlicmd.py --dl-frameworks --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-start tensorflow --rest-host abc.ibm.com rest-port -1 --data-source '[{\"type\": \"fs\", \"location\": {\"paths\": \"mnist\"}}]' --model-main mnist.py\n",
      "   $ python dlicmd.py --exec-get job-12345 --rest-host abc.ibm.com rest-port -1\n",
      "   $ python dlicmd.py --exec-get-all --rest-host abc.ibm.com rest-port -1 --query-args \"limit=10&state=FINISHED&sort_by=id:desc\"\n"
     ]
    }
   ],
   "source": [
    "# for i in range(70, 99):\n",
    "#     %env i=$i\n",
    "#     !python $dlicmd --exec-delete $NAMESPACE-$i --rest-host $HOST --rest-port -1 --jwt-token $USER_ACCESS_TOKEN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a87fd618-0d5d-4f7d-b14c-abf160171a63"
   },
   "source": [
    "### Get Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "id": "5c1ffd65-e531-4fbc-9cef-7d9d47020d24",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"cpd-83\",\n",
      "  \"args\": \"--exec-start distPyTorch --msd-env USER_ACCESS_TOKEN=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IjNMVWFNdUp3UE1nNkhpaTZZQTZrTWhfNWxJYTZlQ0hpbkNtejNzXzBOYUUifQ.eyJ1aWQiOiIxMDAwMzMxMDg5IiwidXNlcm5hbWUiOiJraGFybGFkIiwicm9sZSI6IlVzZXIiLCJwZXJtaXNzaW9ucyI6WyJjcmVhdGVfcHJvamVjdCIsImFjY2Vzc19jYXRhbG9nIiwiYWNjZXNzX2luZm9ybWF0aW9uX2Fzc2V0cyIsInZpZXdfcXVhbGl0eSIsImNyZWF0ZV9zcGFjZSIsIm1hbmFnZV9pbmZvcm1hdGlvbl9hc3NldHMiLCJtYW5hZ2VfbWV0YWRhdGFfaW1wb3J0IiwibWFuYWdlX2Rpc2NvdmVyeSIsIm1hbmFnZV9xdWFsaXR5Iiwidmlld19nb3Zlcm5hbmNlX2FydGlmYWN0cyIsImF1dGhvcl9nb3Zlcm5hbmNlX2FydGlmYWN0cyIsImNhbl9wcm92aXNpb24iLCJzaWduX2luX29ubHkiXSwiZ3JvdXBzIjpbMTAwMDBdLCJzdWIiOiJraGFybGFkIiwiaXNzIjoiS05PWFNTTyIsImF1ZCI6IkRTWCIsImlhdCI6MTY5ODE2NTg1MSwiZXhwIjo1Mjk4MTYyMjUxfQ.jgz8NgOUTCnCdUFS_iR2TuPkAQMCV0c1yPIAhQ783Zl61U5sM0zU65SE-_8wpCCjgdlRdjawTir22Eht-rMdO8M7vfXm84BgBhtEt-408DzB4csMPrwweGZ23yTIugdEeDRtuVOdvY-EeCvNqAk4HDaiKntwQGdEq0EARSz7vCo6cZjipyuxDwdct7v4WmKgVYh-HGvwCXrYZlRYNyUOO6rHPYkPv2JDXNq95KW0IQEiZrRc5dg38XrpgZFa5BoJi7G9GVFZHrepbNbSaArs6qO181YHjWzKr8EmsBt2qUy8TE7PsyRqiuzviqAKot5wNOrhGEblCBXYrLdSAJ6QHg --msd-env BASE_URL=https://cpd-cpd.apps.cpd.mskcc.org --msd-env VOLUME_DISPLAY_NAME=cpd::demo-project-pvc --numWorker 6 --workerMemory 8g --model-dir job_submission --model-main train_command.py \",\n",
      "  \"submissionId\": \"cpd-83\",\n",
      "  \"creator\": \"kharlad\",\n",
      "  \"state\": \"LAUNCHING\",\n",
      "  \"appId\": \"cpd-83\",\n",
      "  \"schedulerUrl\": \"https://wmla-mss.cpd.svc:9080\",\n",
      "  \"modelFileOwnerName\": \"wmla\",\n",
      "  \"workDir\": \"/gpfs/myresultfs/kharlad/batchworkdir/cpd-83/_submitted_code/job_submission\",\n",
      "  \"appName\": \"DistributePyTorchTrain\",\n",
      "  \"createTime\": \"2023-10-25T15:39:33Z\",\n",
      "  \"elastic\": false,\n",
      "  \"nameSpace\": \"cpd\",\n",
      "  \"numWorker\": 6,\n",
      "  \"framework\": \"distPyTorch\",\n",
      "  \"dataSource\": [\n",
      "    {\n",
      "      \"type\": \"fs\",\n",
      "      \"location\": {\n",
      "        \"volume\": \"DeepLIIFData\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"parallelJobInfo\": {\n",
      "    \"status\": {\n",
      "      \"jobStatus\": \"Starting\"\n",
      "    },\n",
      "    \"spec\": [\n",
      "      {\n",
      "        \"taskGroups\": {\n",
      "          \"metadata\": {\n",
      "            \"name\": \"task12n\",\n",
      "            \"annotations\": {\n",
      "              \"lsf.ibm.com/gpu\": \"\"\n",
      "            }\n",
      "          },\n",
      "          \"spec\": {\n",
      "            \"replica\": 6,\n",
      "            \"template\": {\n",
      "              \"spec\": {\n",
      "                \"containers\": {\n",
      "                  \"resources\": {\n",
      "                    \"requests\": {\n",
      "                      \"memory\": \"8192.000000Mi\"\n",
      "                    },\n",
      "                    \"limits\": {\n",
      "                      \"memory\": \"8192.000000Mi\"\n",
      "                    }\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!python $dlicmd --exec-get $APP_ID --rest-host $HOST --rest-port -1 --jwt-token $USER_ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31923da7-9f80-4634-bd8e-4fd99b1ce687"
   },
   "source": [
    "### Get Job Log\n",
    "#### last 10 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "id": "90b9325a-6aa6-402f-872d-91e2482c5025",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python $dlicmd --exec-outlogs $APP_ID --rest-host $HOST --rest-port -1 --jwt-token $USER_ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2d33b3ca-a56c-4087-86f8-396ce81588a5"
   },
   "source": [
    "#### full log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "id": "a84e3f7e-71f8-402e-89ec-81a2ed43633f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!python $dlicmd --exec-trainerrlogs $APP_ID --rest-host $HOST --rest-port -1 --jwt-token $USER_ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "id": "bebbeaca-3020-4513-aac6-b64fdb3aa595",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['inference.log', 'edi_deployments', 'images', 'DeepLIIF_Datasets', 'openscale_metrics', 'deepliif-ws-output', 'model_output_2022-02-08', 'checkpoints']\n",
      "['MNIST', 'deepliif', 'DeepLIIF_Datasets']\n",
      "['mydatafs', 'mygpfs', 'myresultfs']\n",
      "[]\n",
      "['Multi-GPU Training.md', 'setup.py', 'monitor_gpu.sh', 'cli.py', 'LICENSE.md', 'download_data.sh', 'cpd_utils.py', 'environment.yml', 'deepliif', 'Dockerfile', 'PostProcessSegmentationMask.py', 'train_command.py', 'README.md', 'storage_volume_utils.py']\n",
      "/mnts/DeepLIIFData\n",
      "['inference.log', 'edi_deployments', 'images', 'DeepLIIF_Datasets', 'openscale_metrics', 'deepliif-ws-output', 'model_output_2022-02-08', 'checkpoints']\n",
      "/gpfs/myresultfs/kharlad/batchworkdir/cpd-83/_submitted_code/job_submission\n",
      "['MNIST', 'raw']\n",
      "['bin', 'boot', 'dev', 'etc', 'home', 'lib', 'lib64', 'lost+found', 'media', 'mnt', 'opt', 'proc', 'root', 'run', 'sbin', 'srv', 'sys', 'tmp', 'usr', 'var', 'wmla-logging', 'mnts', 'gpfs', 'licenses']\n",
      "['DeepLIIFData']\n",
      "['inference.log', 'edi_deployments', 'images', 'DeepLIIF_Datasets', 'openscale_metrics', 'deepliif-ws-output', 'model_output_2022-02-08', 'checkpoints']\n",
      "['MNIST', 'deepliif', 'DeepLIIF_Datasets']\n",
      "['mydatafs', 'mygpfs', 'myresultfs']\n",
      "[]\n",
      "['Multi-GPU Training.md', 'setup.py', 'monitor_gpu.sh', 'cli.py', 'LICENSE.md', 'download_data.sh', 'cpd_utils.py', 'environment.yml', 'deepliif', 'Dockerfile', 'PostProcessSegmentationMask.py', 'train_command.py', 'README.md', 'storage_volume_utils.py']\n",
      "/mnts/DeepLIIFData\n",
      "['inference.log', 'edi_deployments', 'images', 'DeepLIIF_Datasets', 'openscale_metrics', 'deepliif-ws-output', 'model_output_2022-02-08', 'checkpoints']\n",
      "/gpfs/myresultfs/kharlad/batchworkdir/cpd-83/_submitted_code/job_submission\n",
      "['MNIST', 'raw']\n",
      "['bin', 'boot', 'dev', 'etc', 'home', 'lib', 'lib64', 'lost+found', 'media', 'mnt', 'opt', 'proc', 'root', 'run', 'sbin', 'srv', 'sys', 'tmp', 'usr', 'var', 'wmla-logging', 'mnts', 'gpfs', 'licenses']\n",
      "['DeepLIIFData']\n",
      "['inference.log', 'edi_deployments', 'images', 'DeepLIIF_Datasets', 'openscale_metrics', 'deepliif-ws-output', 'model_output_2022-02-08', 'checkpoints']\n",
      "['MNIST', 'deepliif', 'DeepLIIF_Datasets']\n",
      "['mydatafs', 'mygpfs', 'myresultfs']\n",
      "[]\n",
      "['Multi-GPU Training.md', 'setup.py', 'monitor_gpu.sh', 'cli.py', 'LICENSE.md', 'download_data.sh', 'cpd_utils.py', 'environment.yml', 'deepliif', 'Dockerfile', 'PostProcessSegmentationMask.py', 'train_command.py', 'README.md', 'storage_volume_utils.py']\n",
      "/mnts/DeepLIIFData\n",
      "['inference.log', 'edi_deployments', 'images', 'DeepLIIF_Datasets', 'openscale_metrics', 'deepliif-ws-output', 'model_output_2022-02-08', 'checkpoints']\n",
      "/gpfs/myresultfs/kharlad/batchworkdir/cpd-83/_submitted_code/job_submission\n",
      "['MNIST', 'raw']\n",
      "['bin', 'boot', 'dev', 'etc', 'home', 'lib', 'lib64', 'lost+found', 'media', 'mnt', 'opt', 'proc', 'root', 'run', 'sbin', 'srv', 'sys', 'tmp', 'usr', 'var', 'wmla-logging', 'mnts', 'gpfs', 'licenses']\n",
      "['DeepLIIFData']\n",
      "['inference.log', 'edi_deployments', 'images', 'DeepLIIF_Datasets', 'openscale_metrics', 'deepliif-ws-output', 'model_output_2022-02-08', 'checkpoints']\n",
      "['MNIST', 'deepliif', 'DeepLIIF_Datasets']\n",
      "['mydatafs', 'mygpfs', 'myresultfs']\n",
      "[]\n",
      "['Multi-GPU Training.md', 'setup.py', 'monitor_gpu.sh', 'cli.py', 'LICENSE.md', 'download_data.sh', 'cpd_utils.py', 'environment.yml', 'deepliif', 'Dockerfile', 'PostProcessSegmentationMask.py', 'train_command.py', 'README.md', 'storage_volume_utils.py']\n",
      "/mnts/DeepLIIFData\n",
      "['inference.log', 'edi_deployments', 'images', 'DeepLIIF_Datasets', 'openscale_metrics', 'deepliif-ws-output', 'model_output_2022-02-08', 'checkpoints']\n",
      "/gpfs/myresultfs/kharlad/batchworkdir/cpd-83/_submitted_code/job_submission\n",
      "['MNIST', 'raw']\n",
      "['bin', 'boot', 'dev', 'etc', 'home', 'lib', 'lib64', 'lost+found', 'media', 'mnt', 'opt', 'proc', 'root', 'run', 'sbin', 'srv', 'sys', 'tmp', 'usr', 'var', 'wmla-logging', 'mnts', 'gpfs', 'licenses']\n",
      "['DeepLIIFData']\n",
      "['inference.log', 'edi_deployments', 'images', 'DeepLIIF_Datasets', 'openscale_metrics', 'deepliif-ws-output', 'model_output_2022-02-08', 'checkpoints']\n",
      "['MNIST', 'deepliif', 'DeepLIIF_Datasets']\n",
      "['mydatafs', 'mygpfs', 'myresultfs']\n",
      "[]\n",
      "['Multi-GPU Training.md', 'setup.py', 'monitor_gpu.sh', 'cli.py', 'LICENSE.md', 'download_data.sh', 'cpd_utils.py', 'environment.yml', 'deepliif', 'Dockerfile', 'PostProcessSegmentationMask.py', 'train_command.py', 'README.md', 'storage_volume_utils.py']\n",
      "/mnts/DeepLIIFData\n",
      "['inference.log', 'edi_deployments', 'images', 'DeepLIIF_Datasets', 'openscale_metrics', 'deepliif-ws-output', 'model_output_2022-02-08', 'checkpoints']\n",
      "/gpfs/myresultfs/kharlad/batchworkdir/cpd-83/_submitted_code/job_submission\n",
      "['MNIST', 'raw']\n",
      "['bin', 'boot', 'dev', 'etc', 'home', 'lib', 'lib64', 'lost+found', 'media', 'mnt', 'opt', 'proc', 'root', 'run', 'sbin', 'srv', 'sys', 'tmp', 'usr', 'var', 'wmla-logging', 'mnts', 'gpfs', 'licenses']\n",
      "['DeepLIIFData']\n",
      "['inference.log', 'edi_deployments', 'images', 'DeepLIIF_Datasets', 'openscale_metrics', 'deepliif-ws-output', 'model_output_2022-02-08', 'checkpoints']\n",
      "['MNIST', 'deepliif', 'DeepLIIF_Datasets']\n",
      "['mydatafs', 'mygpfs', 'myresultfs']\n",
      "[]\n",
      "['Multi-GPU Training.md', 'setup.py', 'monitor_gpu.sh', 'cli.py', 'LICENSE.md', 'download_data.sh', 'cpd_utils.py', 'environment.yml', 'deepliif', 'Dockerfile', 'PostProcessSegmentationMask.py', 'train_command.py', 'README.md', 'storage_volume_utils.py']\n",
      "/mnts/DeepLIIFData\n",
      "['inference.log', 'edi_deployments', 'images', 'DeepLIIF_Datasets', 'openscale_metrics', 'deepliif-ws-output', 'model_output_2022-02-08', 'checkpoints']\n",
      "/gpfs/myresultfs/kharlad/batchworkdir/cpd-83/_submitted_code/job_submission\n",
      "['MNIST', 'raw']\n",
      "['bin', 'boot', 'dev', 'etc', 'home', 'lib', 'lib64', 'lost+found', 'media', 'mnt', 'opt', 'proc', 'root', 'run', 'sbin', 'srv', 'sys', 'tmp', 'usr', 'var', 'wmla-logging', 'mnts', 'gpfs', 'licenses']\n",
      "['DeepLIIFData']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python $dlicmd --exec-trainoutlogs $APP_ID --rest-host $HOST --rest-port -1 --jwt-token $USER_ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5321d505-05ba-4d61-a52d-88ba20574aaa"
   },
   "source": [
    "## Others - Visualizer Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2081395a-4eb3-4c2f-a95c-cb6015e3d883",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ws_applications import display_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb16229e-003c-4bab-967e-0a0f58c451b7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_link()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
